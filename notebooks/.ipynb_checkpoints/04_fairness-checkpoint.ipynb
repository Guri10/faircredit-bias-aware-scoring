{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a162f3cd-ce4d-4136-9430-eb99cfc0317c",
   "metadata": {},
   "source": [
    "# Phase 6: Fairness Evaluation & Mitigation\n",
    "\n",
    "We’ll:\n",
    "1. Compute fairness metrics with AIF360 & Fairlearn  \n",
    "2. Apply reweighting to mitigate bias  \n",
    "3. Re-train and compare metrics  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c714ed94-46c9-4286-bdc4-62005c57ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from src.preprocessing import load_data, split_and_preprocess\n",
    "from src.fairness import evaluate_fairness, run_reweighing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06b30f5-11d3-4782-8e64-bd249a68056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load the raw DataFrame\n",
    "df = load_data()\n",
    "\n",
    "# 2) Split raw DataFrame for fairness evaluation\n",
    "df_train_raw, df_test_raw = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"Risk\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Preprocess and split for modeling\n",
    "X_train, X_test, y_train, y_test, preprocessor = split_and_preprocess(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011ab0d-c5ef-4da2-bf1e-01b0724ebab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d1b9bad-fa5d-4f57-bf9d-af52c157edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline AIF360 metrics: {'stat_parity_diff': np.float64(-0.00952380952380949), 'eq_opp_diff': np.float64(0.030000000000000027)}\n",
      "Baseline Fairlearn metrics by group:\n",
      " {'selection_rate': {0: 0.7833333333333333, 1: 0.7928571428571428}, 'true_positive_rate': {0: 0.9, 1: 0.87}}\n"
     ]
    }
   ],
   "source": [
    "# Protected attribute and privileged codes\n",
    "prot_attr = \"Personal_Status_Sex\"\n",
    "priv_cats = [\"A91\", \"A93\", \"A94\"]   # male codes\n",
    "\n",
    "# Train baseline RandomForest\n",
    "clf_base = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_base.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate fairness on the held-out raw test set\n",
    "aif_base, fl_base = evaluate_fairness(\n",
    "    X_test,            # preprocessed features\n",
    "    y_test,            # numeric labels (1=good, 0=bad)\n",
    "    preprocessor,\n",
    "    clf_base,\n",
    "    df_test_raw,       # raw DataFrame (with string codes)\n",
    "    prot_attr=prot_attr,\n",
    "    priv_categories=priv_cats\n",
    ")\n",
    "\n",
    "print(\"Baseline AIF360 metrics:\", aif_base)\n",
    "print(\"Baseline Fairlearn metrics by group:\\n\", fl_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a2a768a-244f-4d53-ab13-1c4fac727f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post‐Reweighing AIF360 metrics: {'stat_parity_diff': np.float64(-0.030952380952380953), 'eq_opp_diff': np.float64(-0.03500000000000003)}\n",
      "Post‐Reweighing Fairlearn metrics by group:\n",
      " {'selection_rate': {0: 0.7833333333333333, 1: 0.8142857142857143}, 'true_positive_rate': {0: 0.875, 1: 0.91}}\n"
     ]
    }
   ],
   "source": [
    "# 1) Get the AIF360 StandardDataset back\n",
    "dataset_rw = run_reweighing(\n",
    "    df_train_raw,\n",
    "    priv_attr=prot_attr,        # note the correct keyword\n",
    "    priv_categories=priv_cats\n",
    ")\n",
    "\n",
    "# 2) Extract the weight array\n",
    "w_train = dataset_rw.instance_weights\n",
    "\n",
    "# 3) Preprocess the raw training features\n",
    "X_rw = preprocessor.fit_transform(df_train_raw.drop(\"Risk\", axis=1))\n",
    "y_rw = df_train_raw[\"Risk\"].map({\"good\": 1, \"bad\": 0}).values\n",
    "\n",
    "# 4) Retrain classifier with those sample weights\n",
    "clf_rw = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rw.fit(X_rw, y_rw, sample_weight=w_train)\n",
    "\n",
    "# 5) Evaluate fairness on the held‐out test split\n",
    "aif_rw, fl_rw = evaluate_fairness(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    X_rw,\n",
    "    clf_rw,\n",
    "    df_test_raw,\n",
    "    prot_attr=prot_attr,\n",
    "    priv_categories=priv_cats\n",
    ")\n",
    "\n",
    "print(\"Post‐Reweighing AIF360 metrics:\", aif_rw)\n",
    "print(\"Post‐Reweighing Fairlearn metrics by group:\\n\", fl_rw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97587b-5895-435a-94e4-89a53edb3d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
